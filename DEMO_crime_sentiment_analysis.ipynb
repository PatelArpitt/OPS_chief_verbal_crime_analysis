{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import PyPDF2, io\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_analysis():\n",
    "    global crimes_data_df\n",
    "    crimes_data_df = pd.DataFrame()\n",
    "    # Read the Excel file\n",
    "    excel_file = 'regular_meetings_v2.3.xlsx'\n",
    "    reports_df = pd.read_excel(excel_file)\n",
    "\n",
    "    # Assuming the column containing PDF links is named 'pdf_urls'\n",
    "    reports_df = reports_df.dropna()\n",
    "    pdf_urls = reports_df[['Date', 'Verbal Report File URL']]\n",
    "\n",
    "    print(pdf_urls)\n",
    "    # Read each PDF\n",
    "    # for pdf_url in pdf_urls:\n",
    "    for index, row in pdf_urls.iterrows():\n",
    "        if index < 15:\n",
    "            resp = requests.get(row['Verbal Report File URL'])\n",
    "            with io.BytesIO(resp.content) as file:\n",
    "                # Create a PDF object\n",
    "                pdf = PyPDF2.PdfReader(file)\n",
    "                \n",
    "                # Initialize a variable to store the extracted text\n",
    "                global corpus\n",
    "                corpus = \"\"\n",
    "                \n",
    "                # Extract the text from each page of the PDF. We have only one page.\n",
    "                for page in pdf.pages:\n",
    "                    corpus += page.extract_text()\n",
    "                \n",
    "            print(\"link started: \", index, row['Verbal Report File URL'])\n",
    "            sentiment_analyzer(corpus, row['Date'])\n",
    "            crimes_data_df = crimes_data_df.append(crime_df)\n",
    "            print(\"link over: \", index, row['Verbal Report File URL'])\n",
    "            print(crimes_data_df)\n",
    "            # Print the extracted text\n",
    "            # print(corpus)\n",
    "        export_excel()\n",
    "    else:\n",
    "        print(\"Demo Analysis Completed! Please check the output file: 'DEMO_crime_analysis_output.xlsx' for the output.\")\n",
    " \n",
    "def sentiment_analyzer(corpus, date):\n",
    "    corpus = corpus.replace(\"\\n\", \" \")\n",
    "    corpus = corpus.lower()\n",
    "    tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "    sentences = tokenizer.tokenize(corpus)\n",
    "    # print(sentences)\n",
    "\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    crime = []\n",
    "    not_crime = []\n",
    "\n",
    "    # Loop through the sentences and determine the sentiment score\n",
    "    for sentence in sentences:\n",
    "        # Get the sentiment score for the sentence\n",
    "        sentiment_score = analyzer.polarity_scores(sentence)\n",
    "        \n",
    "        # Determine if the sentence has a negative sentiment (indicating a crime)\n",
    "        if sentiment_score['neg'] > sentiment_score['pos']:\n",
    "            crime.append(sentence)\n",
    "        else:\n",
    "            not_crime.append(sentence)\n",
    "    # print(crime)\n",
    "    global crime_df\n",
    "    crime_df = pd.DataFrame({'sentences': crime})\n",
    "    crime_df.insert(0, 'Date', date)\n",
    "\n",
    "    # apply the function to the DataFrame for contains_crime()\n",
    "    crime_df['contains_crime'] = crime_df['sentences'].apply(contains_crime)\n",
    "    crime_df = crime_df[crime_df['contains_crime'] == True]\n",
    "    print(crime_df)\n",
    "\n",
    "    #crime_df[\"num_people\"] = crime_df[\"sentences\"].apply(detect_num_people).replace(np.nan, 1).astype(int) for detect_num_people() and detect_crime_type()\n",
    "    crime_df.loc[:, \"num_people_involved\"] = crime_df[\"sentences\"].apply(detect_num_people).replace(np.nan, 1).astype(int)\n",
    "    crime_df.loc[:, \"crime_type\"] = crime_df[\"sentences\"].apply(detect_crime_type)\n",
    "\n",
    "    # Add a new column to the DataFrame with the detected crime type\n",
    "    #crime_df.loc[:, \"crime_type\"] = crime_df[\"sentences\"].apply(detect_crime_type)\n",
    "\n",
    "\n",
    "# function to detect if a sentence contains a crime\n",
    "def contains_crime(sentence):\n",
    "    # load the pre-trained model\n",
    "    # nlp = spacy.load(\"en_core_web_lg\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # example DataFrame\n",
    "    # crime_df = pd.DataFrame(crime_df)\n",
    "\n",
    "    # apply NER to the sentence\n",
    "    crime_words = ['homicide', 'murder', 'kill', 'sexual', 'assault', 'drug', 'shotgun', 'rob', 'criminal', 'charge', 'rape', 'violence', 'attack', 'sexual assault', 'robbery', 'shoot', 'gun']\n",
    "    # crime_tokens = [nlp(word) for word in crime_words]\n",
    "    # crime_vectors = np.vstack([token.vector for token in crime_tokens])\n",
    "    doc = nlp(sentence)\n",
    "    # check for entities labelled as \"CRIME\" or \"LAW\"\n",
    "    for ent in doc.ents:\n",
    "        \n",
    "        if ent.label_ in ['CRIME', 'LAW', 'MURDER', 'PERSON', 'WEAPON', 'MONEY', 'GUN', 'CRIMINAL CHARGES', 'NUMBERS']:\n",
    "            return True\n",
    "    # check for POS tags indicating a violent crime\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB' and token.lemma_ in crime_words:\n",
    "            return True\n",
    "    for token in doc:\n",
    "        for crime_word in crime_words:\n",
    "            if token.similarity(nlp(crime_word)) > 0.6:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # similarities = np.dot(crime_vectors, doc.vector.T) / (np.linalg.norm(crime_vectors) * np.linalg.norm(doc.vector))\n",
    "    # if np.any(similarities > 0.6):\n",
    "    #     return True\n",
    "    # return False\n",
    "\n",
    "\n",
    "# Define a function to detect the type of crime in a sentence\n",
    "def detect_crime_type(sentence):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    homicide_regex = re.compile(r\"(murder|killing|death|homicide|manslaughter|Guns|shooting|died|offenders|firearm|shots|fired|shoot)\", re.IGNORECASE)\n",
    "    stabbing_regex = re.compile(r\"(stabbing|stabbed|knife attack|knife)\", re.IGNORECASE)\n",
    "    police_regex = re.compile(r\"(violance|violent| encounter|police officer|injured|assaulted the officer|constable)\", re.IGNORECASE)\n",
    "    stolen_regex = re.compile(r\"(Theft|stolen|fraud|possesion)\", re.IGNORECASE)\n",
    "    drug_regex = re.compile(r\"(drug|marijuana|substances|cannabis|products|narcotics|overdosing|overdosed)\", re.IGNORECASE)\n",
    "    driving_regex = re.compile(r\"(stunt|driving|licence|demerit|fined|car)\", re.IGNORECASE)\n",
    "    hateful_regex = re.compile(r\"(hateful|hate|speech)\", re.IGNORECASE)\n",
    "    assault_regex = re.compile(r\"(sexual|sexual assault|harassment|harassing|abusing|abuse|threatening|fighting|rape)\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "    if re.search(homicide_regex, sentence):\n",
    "        return \"homicide\"\n",
    "    elif re.search(stabbing_regex, sentence):\n",
    "        return \"stabbing\"\n",
    "    elif re.search(police_regex, sentence):\n",
    "        return \"total assaults against a peace officer\"\n",
    "    elif re.search(stolen_regex, sentence):\n",
    "        return \"total possession of stolen property\"\n",
    "    elif re.search(drug_regex, sentence):\n",
    "        return \"drug violations\"\n",
    "    elif re.search(driving_regex, sentence):\n",
    "        return \"driving violations\"\n",
    "    elif re.search(hateful_regex, sentence):\n",
    "        return \"speech violations\"\n",
    "    elif re.search(assault_regex, sentence):\n",
    "        return \"assault and harrassment\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def detect_num_people(text):\n",
    "    pattern = r\"\\b(\\d+|one|two|three|four|five|six|seven|eight|nine|ten)\\b(?=\\s*(?:for\\s)?(?:criminals?|illicit?|robberies?|arrests?|suspects?|offenders?|men|people|individuals|stunt|criminal|charges))\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        num_str = match.group(1)\n",
    "        if num_str.isdigit():\n",
    "            num = int(num_str)\n",
    "            if num > 100: # Assume it's an age\n",
    "                return None\n",
    "            elif num >= 10 and 'old' in text: # Assume it's an age\n",
    "                return None\n",
    "            else:\n",
    "                return num\n",
    "        elif num_str == 'one':\n",
    "            return 1\n",
    "        elif num_str == 'two':\n",
    "            return 2\n",
    "        elif num_str == 'three':\n",
    "            return 3\n",
    "        elif num_str == 'four':\n",
    "            return 4\n",
    "        elif num_str == 'five':\n",
    "            return 5\n",
    "        elif num_str == 'six':\n",
    "            return 6\n",
    "        elif num_str == 'seven':\n",
    "            return 7\n",
    "        elif num_str == 'eight':\n",
    "            return 8\n",
    "        elif num_str == 'nine':\n",
    "            return 9\n",
    "        elif num_str == 'ten':\n",
    "            return 10\n",
    "    else:\n",
    "        return None\n",
    "      \n",
    "\n",
    "# Print the modified DataFrame\n",
    "def export_excel():\n",
    "    print(crimes_data_df)\n",
    "    output_path = 'DEMO_crime_analysis_output.xlsx'\n",
    "    crimes_data_df.to_excel(output_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
